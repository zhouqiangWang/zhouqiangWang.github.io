[{"title":"philosophy","slug":null,"date":"2017-11-05T09:13:21.000Z","updated":null,"comments":null,"path":"2017/11/05/philosophy/","link":null,"permalink":null,"excerpt":null,"keywords":null,"text":"Excerpt from 《哲学家都干了些什么》 Chapter 9 奇怪的论调 关键是，哲学和科学一样，也有现成的产品呀！那就是充斥在我们生活中的各种各种的人生观。当邻居大妈默念“人的命天注定”的时候，他信奉的是宿命论和决定论；当朋友在酒桌上劝你“赚钱有什么用，钱再多早晚也是一个死”的时候，他讲的是虚无主义；当人生感悟型的散文告诫你“当下最重要，活出你自己”的时候，它其实是萨特的代言人。实际上，整个哲学史上那么多学派那么多学说，凡是和普通人有关系的观点我们都可以在生活中找到它们的通俗版、箴言版、认识感悟版、心有戚戚焉版。我们不需要了解真正的哲学理论，就已经在“享用”哲学家们的思考成果了，并没有什么精妙的哲理是独独藏在哲学著作里，是我们在日常生活中享受不到的。 Chapter 11 笛卡尔是这么想的：他首先有了“我思故我在”这个前提。然后他想，我肯定是存在的，但是我在怀疑，这就意味着我不是完满的。因为完满的东西是不会怀疑的。但是我心中有一个完满的概念，对吧？要不我就不会意识到我是不完满的了。既然我自己是不完满的，那这个完满的概念肯定不能来自我自己，必然来自于一个完满的事物。什么事物是完满的呢？那只能是上帝。好，现在推出这世界上有上帝了。笛卡尔又想，因为上帝是完满的，所以上帝是全知、全能、全善的。既然上帝是全善的，那么上帝一定不会欺骗我，不会让我生活的世界都是幻觉。所以我生活在真实的世界里。证明完毕。 Chapter 12 “世界的本质是什么”的问题，在哲学里又称作“本体论”。“哪些知识是真实可信”的问题，在哲学里又称作“认知论”。 Chapter 12 “形而上学”这个词英文是metaphysics,它的来历是这样的：话说回到古希腊。亚里士多德是个百科全书式的学者，他写过很多的著作，从哲学到物理学，涉及了很多学科。但是那个时候没有现代学术界“哲学”、“物理学”这样的分科。亚里士多德是写痛快了，想研究什么就写什么，可给整理他数据的后人犯愁了。这么一大堆包罗万象的著作，该怎么分类、命名呢？一个叫安德尼科的人想了一个好办法。他用“研究有形体的事物”和“研究没有形体的事物”，把亚里士多德的著作分成了两大类。前一类著作编在一起，起名叫《物理学》。后一类作品，也就是亚里士多德的哲学作品，也编在一起，放在《物理学》的后面。当时没有合适的名字称呼它们，安德尼科一看怎么办呢，就起了一个名字叫metaphysics,意思是“物理学之后”。安德罗尼柯起的这个metaphysics的原本目的，应该是他没有现成的词汇可用，于是就说这部分著作是“编排在《物理学》之后的内容”。但是这个词的含义也可以引申成“物理学之后的学问”，也就是说，形而上学研究的是那些高于物理学的、看不见、摸不着的学问。这就是“形而上学”这个词最早的来历。“形而上学”的中文译名也很棒，称得上是中文翻译史上最棒的译名之一。中文典出《易经》：“形而上者谓之道，形而下者谓之器。” Chapter 13 不过，上述这个人生观又一个痛苦解决不了，那就是我关心的人对我们的负面评价。说白了，二元论可以让你放下压力好好工作。但是当父母因此伤心的时候，二元论就没办法了。从二元论的角度说，他人对我们的评价和我们的精神世界无关，我们完全可以忽视。但是对于我们在乎的人，这点是极难做到饿。一旦做到了，我们也就成了完全不关心任何人的冷血动物。实际上，当我们在乎外人感受的时候，就相当于我们把自己的喜怒哀乐寄托于外物。我们既不可能控制一切外物，我们也不可能让人的感受符合我们的意愿。因此不仅是二元论，其他自我安慰的手段，对于我们所关心的人都有些束手无策。 Chapter 13 二元论 传统的对待生活的方式是，我们想到“考试不及格会给我们带来痛苦”，那我们的对策就是好好念书，努力考试及格。但辛苦念书给我们带来肉体上的痛苦，对考试的担心给我们带来了很强的不安全感，而且就算考试通过了，人又会自动的产生新的欲望和新的焦虑，陷入永无止境的担忧之中。而新的人生观是这样的。我想：不管考试的结果如何，外界对我的这些影响都只体现在我的精神世界里。只要我闭上眼睛，专心驾驭我的内心世界，那么外界发生的任何事情都不会伤害我。这样我也不用费心念书去忍受肉体的痛苦，不用担心考试的结果而惴惴不安，我不为任何外物所扰，反倒清净自在。这是什么境界？说不好听了，这是阿Q的境界；说好听了，这叫“他强由他强，清风拂山岗”，这是九阳神功的境界。 Chapter 13 二元论 世界分成两个部分，一个是我们自己的心灵，一个是心灵之外的部分。这种观点叫作“二元论”，心灵是一个元，外界是一个元，一共二元。这两个元是相互独立的，平等的，虽然可以互相影响，但是也不能完全取决于另一个。因为世界分成二元了，所以这两个元之间是如何联系的，就成了大问题。在后来好几百年中，无数哲学家在“精神世界怎么才能真实反映客观实际”上花费了大量的工夫，也很难有一个令人满意的答案，后来又哲学家反应过来了，直接反对二元论，认为这种划分是我们对世界的一种误解。其中一个反对二元论的学派，就是我们熟悉的唯物主义，说世界的本质是物质的，我们的精神世界不过是大脑生理活动的结果。换句话说，精神是从物质中产生的。这种观点叫作物质一元论。当然，相应的也有唯心主义的一元论，认为世界的本质是精神的，外面的世界不过是我自己心灵的产物。 Chapter 14 简单说，目的论就是认为世间万物是因为某种目的而存在的。比如“史上有苹果是为了给人吃”。这种观念经常被宗教使用。既然上帝创造了世界，那么上帝在设计世界的时候，每一项设计都应该带着某种目的。当然，随着神学的没落，这种目的论很容易遭到抨击。伏尔泰就讽刺说：这么说来，神创造鼻子就是为了架上眼镜啦？但目的论可以成为唯我主义的好朋友。在坚持唯我论的时候，虽然我们相信自己是天下唯一的存在，但是我们还能看、能摸、能感受到世间的一切啊。即便这一切似乎幻觉，那为什么要出现这些幻觉呢？假如我是这世界唯一真实存在的事物，那么很容易想到，或许这些幻觉都是为了我才创造出来的吧。 Chapter 15 寒冬夜行人 当斯宾诺莎意识到自己的幸福应该通过理性思考来追求的时候，他发现，在得出最终答案之前还需要很长时间。那么在这段时间里，自己该怎么生活呢？他总结了几个可以暂时执行的原则，大意是：第一，说话要尽量要别人明白，只要别人对我们的要求不会影响我们实现自己的目标（比如求职），那就尽量满足。只享受为了保持健康所必需的生活乐趣。只求取为生活和健康所必需的金钱。这些生活准则并非出于斯宾诺莎的哲学思考，而是他以一个普通人的身份、一个励志求知的身份思考出来的。这些结论平实朴素，完全就是心灵鸡汤的标准素材。 Chapter 16 双星 事实上，我们今天所取得的所有科学成就，都是综合使用归纳法和演绎推理的结果。这套科学方法既有归纳法，也有演绎推理，但其基础、起关键作用的，是归纳法，科学家们“轻视”演绎推理，关键在于他们发现演绎推理有一个巨大的缺陷，这个缺陷就是，演绎推理不能给我们带来任何新知识。 |理论名称|理性主义|经验主义||-|:-:|-:||代表人物|数学派哲学家|科学派哲学家||研究方法|演绎法|归纳法||优点|严谨|产生新知识||缺点|不产生新知识，公设未必可靠|结论不能保证绝对正确，永远有出错的可能| Chapter 24 远离尘嚣 在康德的哲学世界里，所有知识（也就是来自物体的知识）都要先经过人类心灵的加工，才能被人类认识。所以他自比哲学界的哥白尼，在他的哲学里，不是心灵去感受经验，而是心灵加工经验。当然，这加工过程并不是任意的。我知道您可能还没看懂，能看懂就真不简答！没关系，我们看两个比喻。有一个最常用的比喻，有色眼镜。这个比喻说，假设每个人终身都必须戴着一副蓝色的有色眼镜。这个世界上所有的事物，必须通过有色眼镜的过滤才能被人看到。那么所有人看到的就是一个蓝色的世界，而世界真是的面貌是人永远看不到的。这个比喻里，有色眼镜是先天认识形态，事物原本的颜色是物自体，人类看到的蓝色的世界，是表象。要注意的是，每个人的眼睛都是相同的，不会有人不一样。因而，带着有色眼镜其实不会妨碍人类的正常生活，连物理研究的结论都不会影响。反正颜色只是人类自己起的名字而已，戴眼镜者根本没法察觉到自己的异常。 Chapter 24 远离尘嚣 康的构造的哲学世界观看上去很复杂、很抽象，但其实非常有智慧。康德之前的哲学危机，是休谟对因果律，乃至人类理性理解能力的怀疑。康德的解决方法是，他把世界分成两个部分。一个部分是完全不可知，另一个部分则可以用理性把握，不可知的那部分因为永远不可知，所以对我们的生活没有什么影响。只要我们在可把握的世界里生活，理性就又恢复了威力。这样，既没有破坏休谟的理论（想破坏也没那能力），又让人类重新相信理性，重新踏实了。康德的学说并不是我们完全无关的玄学，而是有很重要的现实意思。假如我们接受康德的世界观，我们就同意，这世上总有一些东西是我们无法认识的。我们只要安于在能认识的世界里生活就对了。这可以用来应对一些没有确凿根据的阴谋论。我们的生活中永远不缺少阴谋论。比如有人说，我们都生活在《黑客帝国》般的虚拟世界里，比如有人说，这世界由神秘组织控制的，比如有人预测某年某月某日是世界末日等等。有的人会觉得，不能证明这些阴谋论为假，就活鹅不踏实。但关键是，很多阴谋论是无法证伪的。我们永远不能证明我们没生活在虚拟世界里；也没法证明我们所看到的世界全是假象；也没法证明，下一秒世界不会被我们从未认识到的某种力量毁灭。按照康德的世界观，这些阴谋论正是处于我们永远无法认识的世界里。那么我们该怎么办？———— 管他作甚！ Chapter 25 王者之风 黑格尔说世间万物的发展一定要符合绝对精神，因此他的绝对精神观是决定论的，他认为历史不是人类创造的，也不是个别事件的堆砌，历史有自己必然的进程，我们人类只是历史实现自己目的的工具。就算拿破仑那样的伟人，其实也是绝对精神的工具。并不是拿破仑自己要征服欧洲，而是绝对精神要利用拿破仑来推进历史的进程。所以，黑格尔表面上赞扬的是拿破仑，其实是在赞扬绝对精神。我们知道，黑格尔鹅历史观后来被马克思批判性的继承了，变成了辩证唯物主义历史观————马克思也认为，历史的进程是有方向的，不可逆、不可阻止的，但是可以预测的。马克思预测历史通向的是共产主义，那么黑格尔的历史通向哪里呢？黑格尔的历史通向绝对精神。他认为宗教比自然科学更高级。最后，绝对精神会通过哲学完成自己的发展，达到最完美的境界。 Chapter 25 王者之风 在黑格尔看来，矛盾的东西是统一的，因此人的理性和客观世界之间虽然是矛盾的，但并不是割裂的，而是可以通过不断辩证统一，最终成为一个合题。这样，人的理性经过辨证运动后，就能喝客观世界合为一体。换句话说，理性经过不断的辨证，就可以完全符合客观世界的真实面貌。理性就是世界的本质，世界的本质是理性。所以说，宇宙的本质是精神，而且是一种理性精神。这个理性精神，就是黑格尔的“绝对精神”。但是，绝对精神不是想领悟就能立刻领悟到的。前面说过，根据黑格尔的辩证法，一切事物都是在不断变化的，而且是有低级到高级的变化，绝对精神也是一样，也在不断由低级到高级变化，也在不断完善自己。运动到最后，绝对精神就能认识自己，自己显示自己，那时候我们才能领悟到绝对精神。还拿那个理性道具和理性石头作比喻。哲学家们不断改造面前的理性石头，每改造一次，手中的工具也跟着变化一次，因此黑格尔之前的哲学家们，疲于奔命。但最终会出现一个完美的状态，面前的理性石头也完美了，手中的理性工具不再是一对矛盾，而是共同升华为合题，成为和谐的一体。那么哲学家们也就完成了改造石头的任务，哲学算是进化到最完美的状态，哲学家们的任务都完成了。所以，黑格尔之前的哲学家们的努力都没白费，他们都为了实现最后的绝对精神作出了必不可少的工作，阶段性的工作。 Chapter 25 王者之风 “绝对精神”也是这样。因此之前的哲学家们不单单是做了打基础的工作，他们的哲学观点虽然并不绝对正确，但也是整理运动过程的一部分。他们也是绝对精神的一部分。因为重视历史过程，黑格尔是第一个重视研究哲学史的人。今天人们学习西方哲学的时候，公认最好的方法是先读一本《西方哲学史》才有资格谈别的，这个风气就是从黑格尔开始的。不过我们今天这么做的理由和黑格尔不大相同：我们的出发点是，哲学是门没有唯一的最终的正确答案的学科，每一个哲学大家的观点都是有道理的，都值得学习和了解。 Chapter 12 逻辑实证主义 维特根斯塔发现，原先用逻辑去分析语言的想法太天真了。比如生活在有人说一句：“我还是我吗？”这话如果用逻辑来分析，那么显然是一句没什么用处的话。然而我们知道，在生活中我们说这句话的时候，有自己的意思，而且不同的情境下还可以代表不止一种意思。如果我们掌握了逻辑分析的方法，到生活中一看，没意义的句子比比皆是。然而老百姓谁管你什么逻辑哲学呀，人家是觉得这句话有意义才说的啊。维根斯坦发现，语言并不能停留在表面的逻辑分析上。同样的一句话，说话的情景不同，说话人的语气、表情、手势不同，常常会表达出不同的意思。换句话说，每一个情景都给语言制定了不同的规则，语言得和规则结合在一起，才能显示真正的意思。而这规则又是没有逻辑可言的。维特根斯坦揭示的，其实是理性思维和现实的矛盾。逻辑实证主义的理想很好，要坚持绝对的理性、绝对的正确，可是最后发现，这个绝对的理性得不到任何有意义的结论，连一个普遍的结论都得不出来。可是另一方面，我们的现实生活时多姿多彩的，我们有灿烂的文化，有日新月异的科学知识。这说明了什么？说明理性根本无法负担从总体上解释世界、指导世界的任务。 Chapter 12 逻辑实证主义 逻辑实证主义者就回答了一个问题：为什么哲学家们对形而上学争论了那么久都没有结果呢？因为他们争论的全都是没有意义、不可能有答案的问题。人们没办法靠实证的方式来解决这些问题。 Chapter 13 实用主义 实用主义在美国很受欢迎，实用主义哲学家也大多是美国人。有人说，这是因为实用主义正好契合了美国人的务实精神——这是好听的说法，难听的说法是美国人世俗功利。但这种实用主义未必不能收到好效果。比如美国的司法采用判例法。意思是，过去类似的案子是怎么判的，这回的案子就参考着判。或许有人认为这过于儿戏了，难道国家制定的法律不是最大的吗？但判例法认为，一次性制订的司法是很难完善的。那么我们就通过每一次的审判，来不断纠正、完善国家的法律。你看，这不正好和实用主义者的真理观吻合吗？再看经济问题。马克思对资本主义经济制度的批判非常尖锐，很多西方政治家都认同他的观点。但是这些西方政治家不认同阶级斗争、暴力革命的路子，觉得这事儿动静太大了（当然，从马克思主义的角度说，是这帮人在维护资产阶级的利益）。所以他们采用了实用主义的方案，一些有社会主义倾向的政党在西方国家兴起。他们不搞武装革命，也不想消除阶级差别，而是搞工会，搞社会福利。不像马克思那样试图从根本上解决问题，而是从小地方一点一点改良，遇到什么问题就解决什么问题。比如资本家对工人压榨得太厉害了，国家就制定法律保护工人。垄断企业影响市场竞争，就制定反垄断法律限制垄断企业。工人购买力下降，就设置最低工资，增加社会福利。实际上，马克思当年为了维护工人阶级利益提出的很多要求，大部分都被资本主义国家接受并且实现了。如今这种改良式的资本主义在西方颇受欢迎，这可以让我们看到实用主义在西方的用处。也不要以为实用主义只有西方人才喜欢。实用主义离我们也不远，有一句话我们很熟悉：“黑猫白猫，能抓住老鼠就是好猫。” Chapter 13 实用主义 胡适在《中国哲学史大纲》中说：“凡研究人生的切要问题，从根本上着想，要寻一个根本的解决，这种学问，叫作哲学。”他所持的，也就是实用主义的哲学观。 Chapter 14 终结形而上学 历史主义的逻辑是，既然自然社会存在规律，那么历史也应该有规律。我们历史主义者像科学家一样揭示了这个规律，人类按照我们揭示的规律奋斗就可以了。但证伪主义认为，没有永恒不变的真理，所有的理论都可能是错的。所以，也就不存在什么“历史的必然规律”。而且科学理论未来的发展方向也是难以预测的。就比如在牛顿时代，没人能够预测相对论的出现，也没人能预测牛顿理论将会在哪里出问题。因此，预测未来的历史规律，一劳永逸地设计一种绝对正确的政治制度，也是不可能的。用钱穆先生的话说：“制度须不断生长，又定须在现实环境要求下生长。”波普尔因此主张应当建立“开放社会”，要求执政者能够广泛接受意见，赋予大众质疑政策的权利。因为执政理论和科学理论一样，永远都可能是错的。必须要不断地接受证伪，才能保证理论的正确。这正是现代民主思想的核心精神。我们有的人可能会简单地以为，民主就是“大家一起投票，多数说了算”，就是“少数服从多数”。其实这种原始的民主制度有极大的缺陷，这个缺陷在雅典人判苏格拉底死刑、法国大革命的屠杀、希特勒被民众选上台等事件中已经暴露无遗，早就被现代社会抛弃了。 我们常说“人民大众的意见最正确”，这句话对吗？在证伪主义看来，这话就有问题。因为证伪主义认为世上没有绝对真理，那怎么可能说某个意见“最正确”呢？就算全世界99%的人同意的一件事，也不能说这件事最正确。否则，布鲁诺时代就不用怀疑地心说了。证伪主义的政治观，最关心的不是谁制定的政策，而是无论谁制定的政策，都不能成为绝对真理。不管是美国总统下的命令还是全世界人民投票的结果，都要给别人留出修改、推翻它的机会。在这种制度下，无论谁被民选上台，也不会给世界造成太大伤害。因为他上台后的个人权力非常有限，哪怕加个税都需要国会批准。他还必须随时面对全国媒体的质疑、随时可能被弹劾、干四年就得重选、干八年就得下台。这制度不能保证总统想出“最正确”的决策，但可以保证一旦总统作出“错误”的决策，举国上下有无数可以阻止它的机会。可以随时“纠错”而不是“多数说了算”，这才是现代民主制度的核心精神。 Chapter 14 证伪主义 现在，世界大部分国家的刑事司法都接受“无罪推定”原则。意思是说，假如没有足够的证据证明一个人是犯罪嫌疑人，那么就应认为他是无罪的。为什么要坚持这个原则呢？除了人权精神外，还可以用证伪主义来解释。如控告某人参与了一起诈骗，如何证伪这句话呢？首先，被告人必须找出被控告这段时间内的所有活动细节，从而证明自己没有和诈骗团伙有过联系。且不说和团伙有过联系又没参与诈骗的人该怎么说吧，就说真没联系过，他又该怎么向法庭彻底证明这一点呢？证明自己没出过门、没见过犯罪嫌疑人？那你有没有可能用电话联络？你没用电话，那有没有用过电子邮件？电子邮件没用过，那你用没用过飞鸽传书，用没用过烽火？你如何证明自己没有在被控告的时间内使用过烽火？找来邻居证明你们家那几天从来没冒过烟吗？邻居说我中午打了一个盹，没看见，那你就算有罪啦？“某人犯过某罪”不可证伪。相反，“某人没犯过某罪”，这个命题是可以证伪的。只要找到他犯罪的证据就可以推翻这个假设了。因此，在都没有充足证据的情况下，在两个命题中，法院只能采信可证伪的后者，而不会采信前者。 Chapter 17 永恒的终结 心理学可以驱散人的负面情绪，让人更充实快乐，这当然是一门很棒的学问。但是心理学不能告诉我们，这世界有没有终极存在，不能告诉我们人生的意义是什么。当心理医生为你解答这些问题的时候，他考虑的不是这些问题的真假，而是该怎么回答才能让你的心里更舒服一点、更健康一点。这是标准的实用主义，对你效果最好的答案，医生就会当成真理告诉你。但是你相信吗？我们不信。我们天生喜欢怀疑，我们不仅追求自己的快乐，我们还想知道真相。同样的道理。面对上述负面情绪，信仰宗教也是最实用的办法，但是在没有有力证据证明神灵存在之前，我们也不信。所以，用实用主义回答出的哲学答案，我们不能接受。实用主义也行不通。那么，还有别的什么办法吗？没有了。在理性的领域里，面对“人生的意义时什么”等等形而上学问题，要么去求助心理医生，要么就没有答案了。这就是本书的结论。如果这本书您看到这里，对有一些地方仍然感到迷迷糊糊，有些地方仍然没看懂，甚至光顾着去看八卦了，那也没有关系。我现在告诉您一句结论，只要记住这句结论，这本书就算没白看（睡觉的同学醒醒，老师划重点了）。这句话是：形而上学走不通，形而上学的问题都没有答案。记住这一句话就够了。我们说过，形而上学的任务，是用理性思维去研究世界本质等“大问题”。形而上学走不通，也就是说，理性不可能回答“世界的本质是什么”“有没有终极真理”“终极真理是什么”“人生的意义是什么”等大问题。硬要回答，答案一定是独断论的，或者在推理上有错误。形而上学家们研究了好几百年，就得出这么一个结论。实际上，所有的形而上学都会陷入无法证明自身的困境。 Chapter 19 西西弗的神话 真实的生活是平淡的。在得知死讯以后，人会因为一时的激情暂时改变对生活的看法，但大脑的自我保护机制决定，人不会长时间保持激情。时间稍微一长，生活又会变成普通的样子。琐碎无聊的生活依旧琐碎无聊。一开始亲朋好友还会对你付出热情的关怀与照顾，但是随着时间延长，热情也会散去，久病床前无孝子，疲惫和厌倦接踵而来。过去让人感到烦躁、无奈、绝望的琐事，会依旧让人烦躁、无奈和绝望。 Chapter 19 西西弗的神话 一个人的一生其实是非常复杂的，在不同阶段有不同的人生目的，同一时期也会同时有很多目的，甚至本人都说不清楚自己的人生目的到底是什么。但是，当我们评价一个人——尤其是比较疏远的人的时候，常常会强行给他（她）安上一个身份（她是一位好母亲）、一个目的（她养育了一大家人），在他（她）人生的结尾，这个人生目的一定会有一个交待（她培养出了一群好儿女/不幸的是，儿女辜负了她），然后我们就完成了对一个人的描述。就像看完一部完整的好莱坞电影一样，心满意足了.问题是，无论人的存在还是毁灭，都是偶然的，根本不可能遵守好莱坞的故事结构。真正的人生，故事忽然开始，忽然结束，不一定有矛盾冲突，也未必有高潮和结局。当人们意识到这一点的时候，就会感到世界荒谬。对于普通人，最能让人感受到这一点的，是死亡到来的时刻。 Chapter 19 西西弗的神话 故事是大部分人理解这个世界的方式。现在请你唤起你对一个熟人的印象，你在头脑里，最先想到的常常是关于这个人的一些事件的片段，而不是理性的一二三四。这是人类进化的一种优势：用故事的方式记忆知识，对智力水平依赖程度低，不容易被遗忘，这在远古时代是最高效的，在现代也是最省力的方式。人生小感悟、心灵鸡汤这类用故事来说教的形式之所以流行，就是这个缘故。 Chapter 20 人生的意义 维特根斯坦在《逻辑哲学论》中说：“人生问题的解答在于对这个问题的消除。”这个道理体现在生活中就相当于，人小的时候要问“人为什么活着”，长大了就不问了，不一定是因为知道答案了，而是因为某些原因让他觉得不再需要问这个问题了。当你不再问这个问题的时候，或许就意味着你已经找到了答案。","raw":null,"content":null,"categories":null,"tags":[{"name":"philosophy","slug":"philosophy","permalink":"http://yoursite.com/tags/philosophy/"}]},{"title":"III","slug":null,"date":"2017-09-11T18:01:19.000Z","updated":null,"comments":null,"path":"2017/09/12/III/","link":null,"permalink":null,"excerpt":null,"keywords":null,"text":"Video #7: Selecting the best model using cross-validationthe drawback of using the train/test split procedure for model evaluation high variance estimate since changing which observations happen to be in the testing set can significantly change testing accuracy Steps for K-fold cross-validation Split the dataset into K equal partitions (or “folds”). Use fold 1 as the testing set and the union of the other folds as the training set. Calculate testing accuracy. Repeat steps 2 and 3 K times, using a different fold as the testing set each time. Use the average testing accuracy as the estimate of out-of-sample accuracy. Comparing cross-validation to train/test splitAdvantages of cross-validation: More accurate estimate of out-of-sample accuracy More “efficient” use of data (every observation is used for both training and testing) Advantages of train/test split: Runs K times faster than K-fold cross-validation Simpler to examine the detailed results of the testing process Cross-validation recommendations K can be any number, but K=10 is generally recommended For classification problems, stratified sampling is recommended for creating the folds Each response class should be represented with equal proportions in each of the K folds scikit-learn’s cross_val_score function does this by default Cross-validation example: parameter tuningGoal: Select the best tuning parameters (aka “hyperparameters”) for KNN on the iris dataset Cross-validation example: model selectionGoal: Compare the best KNN model with logistic regression on the iris dataset Cross-validation example: feature selectionGoal: Select whether the Newspaper feature should be included in the linear regression model on the advertising dataset Improvements to cross-validation Repeated cross-validation Creating a hold-out set Feature engineering and selection within cross-validation iterations Video #8: Efficiently searching for optimal tuning parametersMore efficient parameter tuning using GridSearchCVAllows you to define a grid of parameters that will be searched using K-fold cross-validation Searching multiple parameters simultaneously Example: tuning max_depth and min_samples_leaf for a DecisionTreeClassifier Could tune parameters independently: change max_depth while leaving min_samples_leaf at its default value, and vice versa But, best performance might be achieved when neither parameter is at its default value Using the best parameters to make predictionsReducing computational expense using RandomizedSearchCV Searching many different parameters at once may be computationally infeasible RandomizedSearchCV searches a subset of the parameters, and you control the computational “budget” Important: Specify a continuous distribution (rather than a list of values) for any continous parameters Video #9: Better evaluation of classification modelsModel evaluation procedures Training and testing on the same data Rewards overly complex models that “overfit” the training data and won’t necessarily generalize Train/test split Split the dataset into two pieces, so that the model can be trained and tested on different data Better estimate of out-of-sample performance, but still a “high variance” estimate Useful due to its speed, simplicity, and flexibility K-fold cross-validation Systematically create “K” train/test splits and average the results together Even better estimate of out-of-sample performance Runs “K” times slower than train/test split Model evaluation metrics Regression problems: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error Classification problems: Classification accuracy Classification accuracy Classification accuracy: percentage of correct Null accuracy: accuracy that could be achieved by always predicting the most frequent class Conclusion: Classification accuracy is the easiest classification metric to understand But, it does not tell you the underlying distribution of response values And, it does not tell you what “types” of errors your classifier is making Confusion matrixTable that describes the performance of a classification model Basic terminology True Positives (TP): we correctly predicted that they do have diabetes True Negatives (TN): we correctly predicted that they don’t have diabetes False Positives (FP): we incorrectly predicted that they do have diabetes (a “Type I error”) False Negatives (FN): we incorrectly predicted that they don’t have diabetes (a “Type II error”) Adjusting the classification thresholdDecrease the threshold for predicting diabetes in order to increase the sensitivity of the classifier Sensitivity: When the actual value is positive, how often is the prediction correct? How “sensitive” is the classifier to detecting positive instances?Also known as “True Positive Rate” or “Recall” Specificity: When the actual value is negative, how often is the prediction correct? How “specific” (or “selective”) is the classifier in predicting positive instances? Conclusion: Threshold of 0.5 is used by default (for binary problems) to convert predicted probabilities into class predictions Threshold can be adjusted to increase sensitivity or specificity Sensitivity and specificity have an inverse relationship ROC Curves and Area Under the Curve (AUC)Question: Wouldn’t it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?Answer: Plot the ROC curve! AUC is the percentage of the ROC plot that is underneath the curve: AUC is useful as a single number summary of classifier performance. If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation. AUC is useful even when there is high class imbalance (unlike classification accuracy). Confusion matrix advantages: Allows you to calculate a variety of metrics Useful for multi-class problems (more than two response classes) ROC/AUC advantages: Does not require you to set a classification threshold Still useful when there is high class imbalance (function(d, s) { var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === &apos;function&apos;) { return; } j = d.createElement(s); j.src = &apos;https://cdn-city.livere.com/js/embed.dist.js&apos;; j.async = true; e.parentNode.insertBefore(j, e); })(document, ‘script’); 为正常使用来必力评论功能请激活JavaScript","raw":null,"content":null,"categories":null,"tags":[]},{"title":"model","slug":null,"date":"2017-09-09T11:50:09.000Z","updated":null,"comments":null,"path":"2017/09/09/model/","link":null,"permalink":null,"excerpt":null,"keywords":null,"text":"video 4. Model training and prediction4-step modeling pattern Import the class you plan to use; Instantiate the estimator; Instantiate : make a instance of Estimator : model Fit the model with data(aka “model training”); Predict the response for a new observation Using a different value for KUsing a different classification model video 5. Comparing machine learning modelsEvaluation procedure #1: Train and test on the entire datasetEvaluation procedure #2: Train/test split Split the dataset into two pieces: a training set and a testing set. Train the model on the training set. Test the model on the testing set, and evaluate how well we did.20%~40% of dataset are split as test data. Video #6: Data science pipeline with pandas, seaborn, scikit-learnTypes of supervised learning Classification: Predict a categorical response Regression: Predict a continuous response Reading data using pandas1import pandas as pd 12345# read CSV file directly from a URL and save the resultsdata = pd.read_csv(&apos;./train.csv&apos;, index_col=0)# display the first 5 rowsdata.head() 12# display the last 5 rowsdata.tail() 1data.shape Visualizing data using seabornSeaborn: Python library for statistical data visualization built on top of Matplotlib 1234import seaborn as sb# allow plots to appear within the notebook%matplotlib inline 12# visualize the relationship between the features and the response using scatterplotssns.pairplot(data, x_vars=[&apos;TV&apos;,&apos;Radio&apos;,&apos;Newspaper&apos;], y_vars=&apos;Sales&apos;, size=7, aspect=0.7, kind=&apos;reg&apos;) Linear regressionPros: fast, no tuning required, highly interpretable, well-understood Cons: unlikely to produce the best predictive accuracy (presumes a linear relationship between the features and response) Preparing X and y using pandas Splitting X and y into training and testing sets Linear regression in scikit-learn Interpreting model coefficients Making predictions Model evaluation metrics for regression Mean Absolute Error (MAE) is the mean of the absolute value of the errors: Mean Squared Error (MSE) is the mean of the squared errors: Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors: Comparing these metrics: MAE is the easiest to understand, because it’s the average error. MSE is more popular than MAE, because MSE “punishes” larger errors. RMSE is even more popular than MSE, because RMSE is interpretable in the “y” units. Feature selectionremove some feature from the model and check the RMSE!","raw":null,"content":null,"categories":null,"tags":[]},{"title":"Machine Learning scikit","slug":null,"date":"2017-09-03T09:38:26.000Z","updated":null,"comments":null,"path":"2017/09/03/Machine-Learning-scikit/","link":null,"permalink":null,"excerpt":null,"keywords":null,"text":"video 1. Intro to Machine Learning. What is machine learningsemi-automated extraction of knowledge from data. two main categories of machine learning? supervised - predictive modeling, making predictions using data; unsupervised learning - extract structure from data or learning how to best represent data. two main steps of supervised learning: train a machine learning model using existing labeled data. make prediction on new coming data. video 2. set-up python environment for machine learning video 3. Exploring the Iris datasetMachine learning terminology observation : Each row in dataset(also known as: sample, example, instance, record); feature : Each column in dataset(aka. predictor, attribute, independent variable, input, regressor, covariate); response : Each value we are predicting(aka: target, outcome, label, dependent variable); Classification : supervised learning in which the response is categorical; Regression : supervised learning in which the response is ordered and continuous. Requirements for working with data in scikit-learn Features and response are separate objects; Features and response should be numeric; Features and response should be NumPy arrays; Features and response should have specific shapes.","raw":null,"content":null,"categories":null,"tags":[]},{"title":"Hello World","slug":null,"date":"2016-05-23T20:12:38.000Z","updated":null,"comments":null,"path":"2016/05/24/hello-world/","link":null,"permalink":null,"excerpt":null,"keywords":null,"text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment (function(d, s) { var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === &apos;function&apos;) { return; } j = d.createElement(s); j.src = &apos;https://cdn-city.livere.com/js/embed.dist.js&apos;; j.async = true; e.parentNode.insertBefore(j, e); })(document, ‘script’); 为正常使用来必力评论功能请激活JavaScript","raw":null,"content":null,"categories":null,"tags":[]}]